{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1Yn6YzRW-S8mxB8773lfcUzbd6cmudQRy?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "# Python GPU Programming: Estimating Pi with Monte Carlo Simulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHH_JI_h0HaC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "! pip install pyopencl mako -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9yPcgxt7-bs",
        "outputId": "42536df3-dc75-4882-9d93-1a9f1019c276",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pi Estimate:  3.14179664\n",
            "Time Elapsed:  3.100929021835327\n"
          ]
        }
      ],
      "source": [
        "# NumPy Pi Estimation with Monte Carlo Simulation\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "n_runs = 10**8\n",
        "\n",
        "# Simulate Random Coordinates in Unit Square:\n",
        "ran = np.random.uniform(low=-1, high=1, size=(2, n_runs))\n",
        "\n",
        "# Identify Random Coordinates that fall within Unit Circle and count them\n",
        "result = ran[0]**2 + ran[1]**2 <= 1\n",
        "n_in_circle = np.sum(result)\n",
        "\n",
        "# Estimate Pi\n",
        "print(\"Pi Estimate: \", 4 * n_in_circle / n_runs)\n",
        "\n",
        "print(\"Time Elapsed: \", time.time() - t0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHF-MVR7df3_"
      },
      "source": [
        "## Several GPU Approaches\n",
        "\n",
        "### Create Context and Command Queue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "asL-eiC_dWNU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pyopencl as cl\n",
        "import pyopencl.clrandom as clrand\n",
        "import pyopencl.array as cl_array\n",
        "from pyopencl.elementwise import ElementwiseKernel\n",
        "from pyopencl.reduction import ReductionKernel\n",
        "import time\n",
        "import numpy as np\n",
        " \n",
        "ctx = cl.create_some_context()\n",
        "queue = cl.CommandQueue(ctx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnIBwKTXdrEX"
      },
      "source": [
        "### Map on GPU, Reduce on CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQRNt4BZeWAk",
        "outputId": "6ee424f9-d0a2-4507-d89f-91afe6d4c158",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.14161396\n",
            "Time Elapsed (Map on GPU):  0.23005914688110352\n"
          ]
        }
      ],
      "source": [
        "t0 = time.time()\n",
        "n_runs = 10**8\n",
        "\n",
        "x_dev = clrand.rand(queue, (n_runs), np.float32, a=-1, b=1)\n",
        "y_dev = clrand.rand(queue, (n_runs), np.float32, a=-1, b=1)\n",
        "\n",
        "map_result = (y_dev ** 2 + x_dev ** 2) <= 1\n",
        "n_total = map_result.get()\n",
        "n_in = np.sum(n_total)\n",
        "\n",
        "print(4 * n_in / n_runs)\n",
        "print(\"Time Elapsed (Map on GPU): \", time.time() - t0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkFA9rZYfyAz"
      },
      "source": [
        "\n",
        "### Combined Map/Reduce on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx3LDr6ZfUVE",
        "outputId": "470dae53-f8cb-40d4-ce4f-d5c9fb4c15e3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.1415648\n",
            "Time Elapsed (Map + Reduce on GPU):  0.018733501434326172\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "n_runs = 10**8\n",
        "x_dev = clrand.rand(queue, (n_runs), np.float32, a=-1, b=1)\n",
        "y_dev = clrand.rand(queue, (n_runs), np.float32, a=-1, b=1)\n",
        "\n",
        "rknl = ReductionKernel(ctx, np.float32,\n",
        "        arguments=\"float *x, float *y\",\n",
        "        map_expr=\"(x[i]*x[i] + y[i]*y[i]) <= 1 ? 1 : 0\",\n",
        "        reduce_expr=\"a+b\",\n",
        "        neutral=\"0\",\n",
        "        )\n",
        "\n",
        "n_in = rknl(x_dev, y_dev).get()\n",
        "print(4 * n_in / n_runs)\n",
        " \n",
        "print(\"Time Elapsed (Map + Reduce on GPU): \", time.time() - t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KNBM2QC_0Ys"
      },
      "source": [
        "## Bonus: Abstracting Away Explicit Memory Operations with `numba`\n",
        "\n",
        "In addition to compiling code for CPUs, `numba` also gives us the ability to compile (rudimentary) code for GPUs via similar decorators. Here, we don't need to explicitly deal with transferring data to and from the GPU if we don't want to (although, we will not see the same speedups that PyOpenCL/PyCUDA will give us). Under the hood, `numba` uses CUDA, but we do not need to explicitly write code using CUDA syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "83C_SSyPiWoV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from numba import vectorize, cuda\n",
        "from numba.core.errors import NumbaPerformanceWarning\n",
        "import warnings\n",
        "warnings.simplefilter('ignore', category=NumbaPerformanceWarning)\n",
        "\n",
        "# `numba` has GPU RNG, but only compare map/reduce ops here\n",
        "# see here for example of GPU-side RNG: https://numba.readthedocs.io/en/stable/cuda/random.html\n",
        "n_runs = 10**8\n",
        "ran = np.random.uniform(low=-1, high =1, size=(2, n_runs)).astype(np.float32)\n",
        "x, y = ran[0], ran[1]\n",
        "\n",
        "@vectorize(['i4(f4, f4)'], target='cuda')\n",
        "def in_circle(x, y):\n",
        "  '''\n",
        "  Vectorized function takes in x, y coordinates (float32, float32) within an\n",
        "  array and returns a boolean indication of whether these values are (1) or\n",
        "  are not (0) in the unit circle (int32). All computation is done on the GPU.\n",
        "  '''\n",
        "  in_circle = x**2 + y**2 <= 1\n",
        "  return in_circle\n",
        "\n",
        "@cuda.reduce\n",
        "def gpu_sum(a, b):\n",
        "  '''\n",
        "  Sums values in an array together on the GPU.\n",
        "  '''\n",
        "  return a + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8WySv_eC27e"
      },
      "source": [
        "First, we might try to only perform the mapping operation on the GPU (passing the x and y arrays over to the GPU, computing whether the random coordinates are in the unit circle or not, and then sending values back to the CPU to sum and estimate pi).\n",
        "\n",
        "Note that this is in the same order of magnitude as the GPU Map/CPU Reduce solution above with PyOpenCL (although PyOpenCL/PyCUDA can be a bit faster -- note the times above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yptujAnIxrTI",
        "outputId": "f83ab75d-2325-4051-8914-72f4f421a9a0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "397 ms ± 99.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "result = in_circle(x, y)\n",
        "4 * np.sum(result) / n_runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDbMYIDMC5Rs"
      },
      "source": [
        "Can also perform the summation on the GPU..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06KXRiQptIyO",
        "outputId": "d70a2ac5-4a1c-4acd-9aa8-dfdf217640e9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "298 ms ± 16.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# Perform both in_circle check and sum ops on GPU\n",
        "result = in_circle(x, y)\n",
        "4 * gpu_sum(result) / n_runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlvU-5ftC6Xv"
      },
      "source": [
        "And store intermediate results on the GPU (similar to the `reduce` kernel defined in PyOpenCL above, but adding in some extra complexity):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-Lx56b2tPeM",
        "outputId": "570f47ca-8195-4ff9-ceb7-2a6f35a51ba6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "211 ms ± 23.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# Slight improvement by keeping intermediate result on GPU, but not to the\n",
        "# degree of PyOpenCL's fast map + reduce. Would need to define custom kernel\n",
        "# to match PyOpenCL/PyCUDA's speed with `numba`\n",
        "# (outside the scope of the course: https://numba.pydata.org/numba-doc/latest/cuda/kernels.html)\n",
        "in_circle_dev = cuda.device_array(shape=(n_runs,),\n",
        "                                  dtype=np.float32)\n",
        "in_circle(x, y, out=in_circle_dev)\n",
        "4 * gpu_sum(in_circle_dev) / n_runs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
